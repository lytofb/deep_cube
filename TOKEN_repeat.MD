从日志输出可见，模型在推理阶段一直输出相同的动作 `'B2'`（对应整型 token `17`），直到达到最大步数 `50`，并未复原魔方。**这并不是代码本身的「错误或异常」**，而是一个常见的「模型预测塌缩（collapse）」或「局部最优」现象——也就是说，模型在推理中不断地重复某个动作，从而无法正确复原魔方。

在以下几个方面分析与排查，可以帮助你找到并解决问题：

---

## 1\. 核心原因：模型预测塌缩

**关键点**：代码逻辑本身看上去是正常的，输入（`src`）每一步都根据「滑动窗口」更新，动作输出后也会更新到魔方状态 `cube` 中。  
- **所以技术上推理流程是对的**，只是模型的参数让它倾向于不停地输出同一个动作（如 `'B2'`）。  

此类「单一动作重复」在序列生成任务中很常见，通常和以下几点相关：

1. **模型尚未充分训练或过度简化**  
   - 如果模型学习不到「正确动作分布」，就可能退化到输出某个概率最高的动作（或出现高概率循环）而忽视状态变化。  

2. **数据分布或标签不平衡**  
   - 如果训练数据里 `"B2"` 动作出现得特别多，模型就容易在推理时频繁输出此动作。  

3. **状态编码或输入嵌入有问题**  
   - 如果模型无法区分不同的魔方状态（例如状态向量质量较差、或在训练中状态对模型贡献不大），那么它就会输出最常见/最安全的动作。  

4. **训练方法（损失函数、采样方式、teacher forcing 比例等）**  
   - 如果训练时主要依赖 Teacher Forcing 而推理时是自回归，就可能导致推理分布偏差。  

---

## 2\. 验证：模型输入是否在「真正更新」

在你当前的「迭代推理」实现中，每步都调用：

```python
src = build_src_tensor_from_steps(steps, history_len=history_len)
# ...
logits = model(src, decoder_input)
next_token_id = torch.argmax(last_step_logits, dim=1).item()
# ...
cube(next_move_str)
steps.append((new_state_6x9, next_move_str))
```

这意味着：  
1. **`steps`** 会在每次预测完新动作后新增一条 `(state, move)`；  
2. **`build_src_tensor_from_steps`** 会取最近 `history_len+1` 条 `(state, move)`，编码成与训练一致的输入。  

如果此逻辑确实如你预期更新魔方状态 + move，那么在下一步推理时，模型就能「看到」上一步动作对魔方状态的改变。  

**可以做的检查**：  
- 在推理循环里打印/检查 `cube_to_6x9(cube)` 的内容，看看每一步之后魔方的状态有没有**真实变化**。  
- 在 `steps` 里存储的 `(state, move)` 是否与实际执行的相符？  

如果确认状态都在正常更新，那么就说明**「网络本身」对不同状态并没有学到足够差异化的处理**，从而持续输出同一个动作。

---

## 3\. 从「数据+模型」角度改进

既然代码流程本身没有语法或逻辑错误，那么就要回到「如何让模型学到更好的策略」的问题。常见思路有：

1. **检查数据质量**  
   - 训练数据里是否包含了足够多的多样化打乱、以及对应的解法步骤？  
   - 动作的分布是否极端（某些动作尤其频繁）？  
   - 训练时 `history_len` 的取值、打乱步数区间、样本规模是否足够大？

2. **检查训练超参数**  
   - 学习率、优化器、batch_size、epoch 数量等；  
   - 如果训练不到位，模型可能只学会「瞎猜」或「过拟合」某动作。  

3. **尝试增加「策略探索」或「搜索」技巧**  
   - 例如在推理时使用 **Beam Search** 或者 **温度采样** 而不是纯 Greedy；  
   - 在你已有的 **beam_search** 里可试试增加 `max_steps`，或用更大的 `beam_size`，看能否跳出重复循环。  

4. **减小依赖 Teacher Forcing**  
   - 如果训练中 Teacher Forcing 比例过高，模型习惯在 decoder 中看到正确的历史动作，而推理时则完全靠自身滚动预测，容易出错或坍缩。可尝试逐步降低 Teacher Forcing。  

5. **检查状态输入对模型的贡献**  
   - 你的状态编码 `(54,) -> Embedding -> Transformer` 是否被网络真正有效利用？  
   - 可以对比实验：只用动作序列不带状态，看模型是否也输出固定动作？如果是，那说明状态信息没有被网络「注意」到。  

---

## 4\. 小结

- **目前的单一输出 `'B2'`（token=17）并不表示代码出 bug**，而是模型在推理阶段塌缩到单一动作；  
- 你已经把「每一步魔方新状态、最新 move」写进了 `build_src_tensor_from_steps`，从流程上是正确的；  
- 如果确认每步状态确实在更新，那么这说明模型对状态变化没有捕捉到足够信息，或训练不足，或数据/损失导致它更倾向于输出这个固定动作；  
- 需要从**数据分布**、**训练充分性**、**网络结构**、**推理策略**等多维度改进，才有机会让模型摆脱「无限输出同一动作」的情况。

换言之——**代码基本正确，但「AI 只会一招」**，要让它学到更多、多样化、且能成功复原魔方，需要进一步提升训练数据质量与模型训练策略。